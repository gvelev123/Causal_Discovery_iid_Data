{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18ddc70",
   "metadata": {},
   "source": [
    "### **This notebook demonstrates the following:** \n",
    "1) Simulation of i.i.d. data with nonlinear, nonidentifiable causal transformations.<br><br>\n",
    "2) Application of the 14 causal disocvery techniques included in our benchmark study on a demo version of the simulated datasets, i.e., <br>a small portion of them.<br><br>\n",
    "3) Evaluation of inferred graphs using the six-dimensional performance indicator DOS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87a7068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 11:07:31,101 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\castle\\backend\\__init__.py[line:36] - INFO: You can use `os.environ['CASTLE_BACKEND'] = backend` to set the backend(`pytorch` or `mindspore`).\n",
      "2024-11-30 11:07:31,167 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\castle\\algorithms\\__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "#Relevant imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "#Data simulation imports:\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Data_Simulation_Framework.IID_Data_Generation_Process import lin_func,relu_func, Data_Generation_Process\n",
    "from Results_Visualization.Visualization_Tools import plot_sf_er_graph_NodesEdgesMapping\n",
    "from Causal_Discovery_Models.Causal_Discovery import Causal_Discovery\n",
    "from Src.Utils import python_pickle_to_rds_r\n",
    "from Performance_Evaluation_Framework.Explainable_Boosting_Machine import EBM\n",
    "from Performance_Evaluation_Framework.Multidimensional_Performance_Indicator import DOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c8b86",
   "metadata": {},
   "source": [
    "### **1. Simulation of i.i.d. Data with nonlinear, nonidentifiable causal Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the data generator instance with the parameter values for each of the seven experimental factors \n",
    "#included in our benchmark study:\n",
    "nonlinear_pattern='ReLU'\n",
    "nonlinearities=[[(1.0,lin_func)],#linear patterns only\n",
    "                [(0.5,lin_func),(0.5,relu_func)],#equal probability\n",
    "               [(0.3,lin_func),(0.7,relu_func)],#70% probability relu\n",
    "                [(0.1,lin_func),(0.9,relu_func)]]#90% probability relu\n",
    "\n",
    "data_generator=Data_Generation_Process(beta_lower_limit=0.5,\n",
    "                betta_upper_limit_values=[1.0,2.0,3.0,4.0],\n",
    "                cont_noise=1.0,\n",
    "                nr_nodes_values=[10,20,50,100],\n",
    "                edge_desnity_values=[0.2,0.3,0.4],\n",
    "                data_scale_values=['original','standardized'],\n",
    "                num_samples=2500,\n",
    "                nonlinearities=nonlinearities)\n",
    "\n",
    "#First simulate the i.i.d. datasets based on the ER graph model:\n",
    "er_simulation=data_generator.large_scale_simulation(graph_type='ER')\n",
    "\n",
    "#Save large sample size ER-base data:\n",
    "data_generator.save_data(frames_descriptions=er_simulation[0],\n",
    "                         true_causal_matrices=er_simulation[1],true_weighted_causal_matrices=er_simulation[2],\n",
    "                         frames=er_simulation[3],nonlinear_pattern=nonlinear_pattern,\n",
    "                         graph_type='ER',sample_size='Large_Sample_Size',\n",
    "                         save_path='../Data_Simulation_Framework/Simulated_Datasets/')\n",
    "\n",
    "#Save small sample size ER-based data:\n",
    "data_generator.save_data(frames_descriptions=er_simulation[0],\n",
    "                         true_causal_matrices=er_simulation[1],true_weighted_causal_matrices=er_simulation[2],\n",
    "                         frames=er_simulation[3],nonlinear_pattern=nonlinear_pattern,\n",
    "                         graph_type='ER',sample_size='Small_Sample_Size',\n",
    "                         save_path='../Data_Simulation_Framework/Simulated_Datasets/')\n",
    "\n",
    "#Prepare avg number of edges per number of nodes for SF graph type based on already simulated ER connections:\n",
    "avg_number_edges=data_generator.get_avg_number_edges_ER_graph(frames_descriptions=er_simulation[0],\n",
    "                                                             save_path_edge_mapping='../Performance_Evaluation_Framework/Results/Avg_Number_Edges.pkl')\n",
    "\n",
    "#Simulate SF-based data:\n",
    "sf_simulation=data_generator.large_scale_simulation(graph_type='SF',avg_number_edges=avg_number_edges)\n",
    "\n",
    "#Save large sample size SF-based data:\n",
    "data_generator.save_data(frames_descriptions=sf_simulation[0],\n",
    "                         true_causal_matrices=sf_simulation[1],true_weighted_causal_matrices=sf_simulation[2],\n",
    "                         frames=sf_simulation[3],nonlinear_pattern=nonlinear_pattern,\n",
    "                         graph_type='SF',sample_size='Large_Sample_Size',\n",
    "                         save_path='../Data_Simulation_Framework/Simulated_Datasets/')\n",
    "\n",
    "#Save small sample size SF-based data:\n",
    "data_generator.save_data(frames_descriptions=sf_simulation[0],\n",
    "                         true_causal_matrices=sf_simulation[1],true_weighted_causal_matrices=sf_simulation[2],\n",
    "                         frames=sf_simulation[3],nonlinear_pattern=nonlinear_pattern,\n",
    "                         graph_type='SF',sample_size='Small_Sample_Size',\n",
    "                         save_path='../Data_Simulation_Framework/Simulated_Datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sf_er_graph_NodesEdgesMapping(er_frames_descriptions=er_simulation[0],\n",
    "                                      sf_frames_descriptions=sf_simulation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40625f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate 40 datasets with increased beta upper limit:\n",
    "beta_upper_limit_generator=Data_Generation_Process(beta_lower_limit=0.5,\n",
    "                betta_upper_limit_values=[1.0,4.0,6.0,8.0],\n",
    "                cont_noise=1.0,nr_nodes_values=[20],\n",
    "                edge_desnity_values=[0.3],data_scale_values=['original'],\n",
    "                num_samples=2500,nonlinearities=[[(0.1,lin_func),(0.9,relu_func)]])\n",
    "\n",
    "betas_simulaiton=beta_upper_limit_generator.large_scale_simulation(graph_type='SF',avg_number_edges={'Nodes_20':{0.3:avg_number_edges['Nodes_20'][0.3]}})\n",
    "\n",
    "beta_upper_limit_generator.save_data(frames_descriptions=betas_simulaiton[0],\n",
    "                         true_causal_matrices=betas_simulaiton[1],true_weighted_causal_matrices=betas_simulaiton[2],\n",
    "                         frames=betas_simulaiton[3],nonlinear_pattern=nonlinear_pattern,\n",
    "                         graph_type='SF',sample_size='Large_Sample_Size',\n",
    "                         save_path='../Data_Simulation_Framework/Simulated_Datasets/Betas_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9e91c",
   "metadata": {},
   "source": [
    "### **2. Application of Causal Discovery Models on demo-version, i.e., smaller proportion of the simulated Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6dfcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data_Simulation_Framework/Simulated_Datasets/ER_Large_Sample_Size_Datasets_ReLU_10_nodes.pkl','rb') as f:\n",
    "    frames_list=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef05956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DASK Client Dashboard Link:  http://127.0.0.1:8787/status\n",
      "Using default cache_path: `C:\\Users\\Georg Velev\\Desktop\\Humboldt Uni\\CSL_Benchmark_Study\\Causal_Discovery_iid_Data\\Src\\cache`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 22:12:42,055 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\jax\\_src\\xla_bridge.py[line:622] - INFO: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2024-11-28 22:12:42,057 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\jax\\_src\\xla_bridge.py[line:622] - INFO: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2024-11-28 22:12:42,064 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\jax\\_src\\xla_bridge.py[line:622] - INFO: Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2024-11-28 22:12:42,065 - C:\\Users\\Georg Velev\\anaconda3\\lib\\site-packages\\jax\\_src\\xla_bridge.py[line:636] - WARNING: No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "causal_discovery=Causal_Discovery(frames_list=frames_list[:3],#taking only the first three simulated datasets\n",
    "                                  #for demonstration purposes.\n",
    "                                  index_frame_description=0,\n",
    "                                  index_true_adjacency=1,\n",
    "                                  index_true_weighted_adjacency=2,\n",
    "                                  index_frame=3)\n",
    "causal_discovery.extract_causal_graphs()\n",
    "causal_discovery_demo=causal_discovery.causal_discovery_results\n",
    "causal_discovery_demo_rds=[csl_itm.copy() for csl_itm in causal_discovery_demo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be92a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the the results in RDS format:\n",
    "save_file_path='../Performance_Evaluation_Framework/Results/Causal_Discovery_Results_Demo.rds'\n",
    "python_pickle_to_rds_r(frames_list=causal_discovery_demo_rds,save_path=save_file_path)\n",
    "#Run the script Hybrid_Bayesian_Networks.R in the folder Causal_Discovery_Models in order to\n",
    "#collect the results for the same file from bayesian hybrid networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1863d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append Results from hybrid bayesian networks computed in R to the python results list:\n",
    "with open('../Performance_Evaluation_Framework/Results/Causal_Discovery_Results_Demo_Hybrid_Bayesian_Networks.pkl','rb') as f:\n",
    "    causal_discovery_demo_hbn=pickle.load(f)\n",
    "\n",
    "for csl_index in range(0,len(causal_discovery_demo)):\n",
    "    #Convert the rds-to-pickle dataframe in python format and compare it to the frames in the python file,\n",
    "    #to make sure that the results from hybrid bayesian networks are mapped to those from the other models:\n",
    "    rds_frame=causal_discovery_demo_hbn[csl_index]['dataset']\n",
    "    cols_array=[int(col) for col in rds_frame.columns]\n",
    "    rds_frame.columns=cols_array\n",
    "    indices=[int(index_value) for index_value in rds_frame.index]\n",
    "    rds_frame.index=indices\n",
    "\n",
    "    if causal_discovery_demo[csl_index][3].equals(rds_frame):\n",
    "        causal_discovery_demo[csl_index][-1]['pctabu']=causal_discovery_demo_hbn[csl_index]['pctabu']\n",
    "        causal_discovery_demo[csl_index][-1]['mmtabu']=causal_discovery_demo_hbn[csl_index]['mmtabu']\n",
    "        causal_discovery_demo[csl_index][-1]['fedtabu']=causal_discovery_demo_hbn[csl_index]['fedtabu']\n",
    "    else:\n",
    "        print('Mismatch found at index: ',csl_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfca7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwrite the frames list with all results in the instance of causal discovery & save it in the result folder:\n",
    "causal_discovery.set_causal_discovery_results(current_csl_results=causal_discovery_demo)\n",
    "causal_discovery.save_csl_results(save_path='../Performance_Evaluation_Framework/Results/Causal_Discovery_Results_Demo.pkl',\n",
    "                                 save_for_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8f0ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(causal_discovery_demo[0][-1].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7a71f",
   "metadata": {},
   "source": [
    "### **3. Evaluation of inferred Graphs with the six-dimensional DOS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20567ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Sample Size:  Large_Sample_Size \n",
      "\n",
      "Current Number Nodes:  10_nodes \n",
      "\n",
      "- Current CSL Result Index:  1 from a total of  3\n",
      "- Current CSL Result Index:  2 from a total of  3\n",
      "- Current CSL Result Index:  3 from a total of  3\n"
     ]
    }
   ],
   "source": [
    "dataset_description_index=0\n",
    "true_binary_adjacency_index=1\n",
    "estimated_adjacencies_index=4\n",
    "fpr_metric='NoTears'\n",
    "\n",
    "sample_sizes=['Large_Sample_Size']#,'Small_Sample_Size']\n",
    "number_nodes=['10_nodes']#,'20_nodes','50_nodes','100_nodes']\n",
    "model_names=['NoTears', 'Gran-DAG', 'GOLEM',\n",
    "             'NoCurl', 'AVICI','DIRECT-LINGAM',\n",
    "             'DAGMA', 'NoTears_Nonlinear',\n",
    "             'R2SortnRegress', 'DAS', 'PC_stable',\n",
    "            'fedtabu','pctabu','mmtabu']\n",
    "\n",
    "metrics=['tpr','fpr','normalized_shd',\n",
    "         'f1_score','causal_order_divergence','normalized_sid']\n",
    "best_scenario=np.array([1.0,0.0,0.0,\n",
    "                        1.0,0.0,0.0])\n",
    "worst_scenario=np.array([0.0,1.0,1.0,\n",
    "                         0.0,1.0,1.0])\n",
    "parallelization=True\n",
    "file_path='../Performance_Evaluation_Framework/Results/'\n",
    "\n",
    "DOS_evaluation=DOS(dataset_description_index=dataset_description_index,\n",
    "                true_binary_adjacency_index=true_binary_adjacency_index,\n",
    "                estimated_adjacencies_index=estimated_adjacencies_index,\n",
    "                fpr_metric=fpr_metric,\n",
    "                sample_sizes=sample_sizes,\n",
    "                number_nodes=number_nodes,\n",
    "                model_names=model_names,\n",
    "                metrics=metrics,\n",
    "                best_scenario=best_scenario,\n",
    "                worst_scenario=worst_scenario,\n",
    "                read_path=file_path,\n",
    "                read_file_names=['Causal_Discovery_Results_Demo_Evaluation.pkl'],\n",
    "                #for all results replace with ['ER_CSL_Results.pkl','SF_CSL_Results.pkl'] \n",
    "                save_path=file_path,\n",
    "                save_file_names=['Causal_Discovery_Results_Demo_Evaluation.pkl'])\n",
    "                #for all results evaluations replace with ['ER_CSL_Results_Evaluation.pkl','SF_CSL_Results_Evaluation.pkl']\n",
    "\n",
    "DOS_evaluation.evaluate()\n",
    "DOS_evaluation.create_results_dataframe(save_results_frame_name='Results_Demo_Frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462cfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=DOS_evaluation.results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e84c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr_Run</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Connectivity</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Transformation_Function</th>\n",
       "      <th>Beta_Upper_Limit</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Graph_Type</th>\n",
       "      <th>Sample_Size</th>\n",
       "      <th>CSL_Model</th>\n",
       "      <th>DOS</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>nSHD</th>\n",
       "      <th>FScore</th>\n",
       "      <th>DAG_Check</th>\n",
       "      <th>Eliminated_Edges</th>\n",
       "      <th>Causal_Order_Divergence</th>\n",
       "      <th>nSID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>NoTears</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>Gran-DAG</td>\n",
       "      <td>0.684478</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>GOLEM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>NoCurl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>AVICI</td>\n",
       "      <td>0.878164</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>DIRECT-LINGAM</td>\n",
       "      <td>0.733224</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>DAGMA</td>\n",
       "      <td>0.856450</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.122222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>NoTears_Nonlinear</td>\n",
       "      <td>0.904697</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>R2SortnRegress</td>\n",
       "      <td>0.933086</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Linear_100%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>original</td>\n",
       "      <td>ER</td>\n",
       "      <td>Large_Sample_Size</td>\n",
       "      <td>DAS</td>\n",
       "      <td>0.922215</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr_Run  Nodes  Connectivity  Edges Transformation_Function  \\\n",
       "0       0     10           0.2     12             Linear_100%   \n",
       "1       0     10           0.2     12             Linear_100%   \n",
       "2       0     10           0.2     12             Linear_100%   \n",
       "3       0     10           0.2     12             Linear_100%   \n",
       "4       0     10           0.2     12             Linear_100%   \n",
       "5       0     10           0.2     12             Linear_100%   \n",
       "6       0     10           0.2     12             Linear_100%   \n",
       "7       0     10           0.2     12             Linear_100%   \n",
       "8       0     10           0.2     12             Linear_100%   \n",
       "9       0     10           0.2     12             Linear_100%   \n",
       "\n",
       "   Beta_Upper_Limit     Scale Graph_Type        Sample_Size  \\\n",
       "0               1.0  original         ER  Large_Sample_Size   \n",
       "1               1.0  original         ER  Large_Sample_Size   \n",
       "2               1.0  original         ER  Large_Sample_Size   \n",
       "3               1.0  original         ER  Large_Sample_Size   \n",
       "4               1.0  original         ER  Large_Sample_Size   \n",
       "5               1.0  original         ER  Large_Sample_Size   \n",
       "6               1.0  original         ER  Large_Sample_Size   \n",
       "7               1.0  original         ER  Large_Sample_Size   \n",
       "8               1.0  original         ER  Large_Sample_Size   \n",
       "9               1.0  original         ER  Large_Sample_Size   \n",
       "\n",
       "           CSL_Model       DOS       TPR       FPR      nSHD    FScore  \\\n",
       "0            NoTears  1.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "1           Gran-DAG  0.684478  0.416667  0.000000  0.411765  0.588235   \n",
       "2              GOLEM  1.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "3             NoCurl  1.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "4              AVICI  0.878164  0.833333  0.025641  0.125000  0.833333   \n",
       "5      DIRECT-LINGAM  0.733224  0.666667  0.064103  0.200000  0.640000   \n",
       "6              DAGMA  0.856450  0.833333  0.038462  0.120000  0.800000   \n",
       "7  NoTears_Nonlinear  0.904697  0.916667  0.038462  0.115385  0.846154   \n",
       "8     R2SortnRegress  0.933086  0.916667  0.012821  0.041667  0.916667   \n",
       "9                DAS  0.922215  0.916667  0.025641  0.120000  0.880000   \n",
       "\n",
       "   DAG_Check  Eliminated_Edges  Causal_Order_Divergence      nSID  \n",
       "0       True                 0                 0.000000  0.000000  \n",
       "1       True                 0                 0.000000  0.233333  \n",
       "2       True                 0                 0.000000  0.000000  \n",
       "3       True                 0                 0.000000  0.000000  \n",
       "4       True                 0                 0.083333  0.111111  \n",
       "5       True                 0                 0.333333  0.233333  \n",
       "6       True                 0                 0.166667  0.122222  \n",
       "7       True                 0                 0.083333  0.055556  \n",
       "8       True                 0                 0.083333  0.066667  \n",
       "9       True                 0                 0.000000  0.033333  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b802f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
